% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/recognizer.R
\name{OfflineRecognizer}
\alias{OfflineRecognizer}
\title{Offline Speech Recognizer}
\description{
R6 class for offline speech recognition using sherpa-onnx.
Supports multiple model architectures including Whisper, Paraformer,
SenseVoice, and Transducer models.
}
\examples{

## ------------------------------------------------
## Method `OfflineRecognizer$new`
## ------------------------------------------------

\dontrun{
# Create recognizer with shorthand (auto-detects threads)
rec <- OfflineRecognizer$new(model = "whisper-tiny")

# Create recognizer with specific thread count
rec <- OfflineRecognizer$new(model = "whisper-tiny", num_threads = 4)

# Create recognizer with HuggingFace repo
rec <- OfflineRecognizer$new(
  model = "csukuangfj/sherpa-onnx-whisper-tiny.en"
)

# Create recognizer with local model
rec <- OfflineRecognizer$new(model = "/path/to/model")
}

## ------------------------------------------------
## Method `OfflineRecognizer$transcribe`
## ------------------------------------------------

\dontrun{
rec <- OfflineRecognizer$new(model = "whisper-tiny")
result <- rec$transcribe("audio.wav")

# Print with custom format
print(result)

# Access fields (backward compatible)
cat("Transcription:", result$text, "\n")

# Extract text
text <- as.character(result)

# Detailed information
summary(result)

# Long audio with VAD
result <- rec$transcribe("podcast.wav", use_vad = TRUE)
print(result)  # Shows full text
result$segments  # Individual speech segments
result$segment_starts  # Timing of each segment
}

## ------------------------------------------------
## Method `OfflineRecognizer$transcribe_batch`
## ------------------------------------------------

\dontrun{
rec <- OfflineRecognizer$new(model = "whisper-tiny")
results <- rec$transcribe_batch(c("file1.wav", "file2.wav"))

# Access results via tibble columns
print(results$text)
print(results$file[1])

# Access list-columns
first_tokens <- results$tokens[[1]]
}

## ------------------------------------------------
## Method `OfflineRecognizer$model_info`
## ------------------------------------------------

\dontrun{
rec <- OfflineRecognizer$new(model = "whisper-tiny")
info <- rec$model_info()
print(info)
}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-OfflineRecognizer-new}{\code{OfflineRecognizer$new()}}
\item \href{#method-OfflineRecognizer-transcribe}{\code{OfflineRecognizer$transcribe()}}
\item \href{#method-OfflineRecognizer-transcribe_batch}{\code{OfflineRecognizer$transcribe_batch()}}
\item \href{#method-OfflineRecognizer-model_info}{\code{OfflineRecognizer$model_info()}}
\item \href{#method-OfflineRecognizer-clone}{\code{OfflineRecognizer$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-OfflineRecognizer-new"></a>}}
\if{latex}{\out{\hypertarget{method-OfflineRecognizer-new}{}}}
\subsection{Method \code{new()}}{
Create a new offline recognizer
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{OfflineRecognizer$new(
  model = "parakeet-v3",
  language = "auto",
  num_threads = NULL,
  provider = "cpu",
  verbose = TRUE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{model}}{Model specification. Can be:
- A shorthand string: "parakeet-v3", "whisper-tiny", "whisper-base", "sense-voice"
- A HuggingFace repository: "csukuangfj/sherpa-onnx-whisper-tiny.en"
- A local directory path containing model files}

\item{\code{language}}{Language code for multilingual models (default: "auto").
Used for Whisper and SenseVoice models.}

\item{\code{num_threads}}{Number of threads for inference (default: NULL = auto-detect).
If NULL, uses parallel::detectCores() with a maximum of 4 threads.}

\item{\code{provider}}{Execution provider: "cpu", "cuda", or "coreml" (default: "cpu")}

\item{\code{verbose}}{Logical, whether to print status messages (default: TRUE)}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A new OfflineRecognizer object
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{\dontrun{
# Create recognizer with shorthand (auto-detects threads)
rec <- OfflineRecognizer$new(model = "whisper-tiny")

# Create recognizer with specific thread count
rec <- OfflineRecognizer$new(model = "whisper-tiny", num_threads = 4)

# Create recognizer with HuggingFace repo
rec <- OfflineRecognizer$new(
  model = "csukuangfj/sherpa-onnx-whisper-tiny.en"
)

# Create recognizer with local model
rec <- OfflineRecognizer$new(model = "/path/to/model")
}
}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-OfflineRecognizer-transcribe"></a>}}
\if{latex}{\out{\hypertarget{method-OfflineRecognizer-transcribe}{}}}
\subsection{Method \code{transcribe()}}{
Transcribe a WAV file
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{OfflineRecognizer$transcribe(
  wav_path,
  use_vad = FALSE,
  vad_threshold = 0.5,
  vad_min_silence = 0.5,
  vad_min_speech = 0.25,
  vad_max_speech = 30,
  vad_model = "silero-vad",
  verbose = TRUE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{wav_path}}{Path to WAV file (must be 16kHz, 16-bit, mono)}

\item{\code{use_vad}}{Logical. If TRUE, uses Voice Activity Detection to split
long audio files at natural pauses. Recommended for files longer than
30 seconds. Default: FALSE (transcribe entire file at once).}

\item{\code{vad_threshold}}{Speech detection threshold (0-1). Lower = more sensitive.
Default: 0.5}

\item{\code{vad_min_silence}}{Minimum silence duration (seconds) to split segments.
Default: 0.5}

\item{\code{vad_min_speech}}{Minimum speech duration (seconds) to keep segment.
Default: 0.25}

\item{\code{vad_max_speech}}{Maximum speech duration (seconds) before force split.
Default: 30.0. Useful to prevent memory issues with very long speech.}

\item{\code{vad_model}}{VAD model to use. Default: "silero-vad" (auto-downloaded)}

\item{\code{verbose}}{Logical. Show progress messages. Default: TRUE}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A sherpa_transcription object (list-like) containing:
  - text: Transcribed text
  - tokens: Character vector of tokens (if not using VAD)
  - timestamps: Numeric vector of timestamps (if supported by model)
  - durations: Numeric vector of token durations (if supported by model)
  - language: Detected language (if supported by model)
  - emotion: Detected emotion (if supported by model)
  - event: Detected audio event (if supported by model)
  - json: Full result as JSON string (if not using VAD)
  - segments: Character vector of segment texts (if VAD used)
  - segment_starts: Start times of segments in seconds (if VAD used)
  - segment_durations: Duration of segments in seconds (if VAD used)
  - num_segments: Number of segments (if VAD used)

  The result has a custom print method but maintains list-like access
  (e.g., `result$text`). Use `as.character(result)` to extract just the
  text, or `summary(result)` for detailed statistics.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{\dontrun{
rec <- OfflineRecognizer$new(model = "whisper-tiny")
result <- rec$transcribe("audio.wav")

# Print with custom format
print(result)

# Access fields (backward compatible)
cat("Transcription:", result$text, "\n")

# Extract text
text <- as.character(result)

# Detailed information
summary(result)

# Long audio with VAD
result <- rec$transcribe("podcast.wav", use_vad = TRUE)
print(result)  # Shows full text
result$segments  # Individual speech segments
result$segment_starts  # Timing of each segment
}
}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-OfflineRecognizer-transcribe_batch"></a>}}
\if{latex}{\out{\hypertarget{method-OfflineRecognizer-transcribe_batch}{}}}
\subsection{Method \code{transcribe_batch()}}{
Transcribe multiple WAV files in batch
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{OfflineRecognizer$transcribe_batch(wav_paths)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{wav_paths}}{Character vector of WAV file paths}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Tibble with one row per file and columns:
  - file: Input file path (character)
  - text: Transcribed text (character)
  - tokens: List-column of token character vectors
  - timestamps: List-column of timestamp numeric vectors (or NULL)
  - durations: List-column of duration numeric vectors (or NULL)
  - language: Detected language (character, NA if not available)
  - emotion: Detected emotion (character, NA if not available)
  - event: Detected audio event (character, NA if not available)
  - json: Full result as JSON string (character)
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{\dontrun{
rec <- OfflineRecognizer$new(model = "whisper-tiny")
results <- rec$transcribe_batch(c("file1.wav", "file2.wav"))

# Access results via tibble columns
print(results$text)
print(results$file[1])

# Access list-columns
first_tokens <- results$tokens[[1]]
}
}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-OfflineRecognizer-model_info"></a>}}
\if{latex}{\out{\hypertarget{method-OfflineRecognizer-model_info}{}}}
\subsection{Method \code{model_info()}}{
Get model information
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{OfflineRecognizer$model_info()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
List with model metadata including:
  - type: "local" or "huggingface"
  - path: Local path to model files
  - model_type: Type of model (whisper, paraformer, sense-voice, transducer)
  - repo: HuggingFace repository (if applicable)
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{\dontrun{
rec <- OfflineRecognizer$new(model = "whisper-tiny")
info <- rec$model_info()
print(info)
}
}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-OfflineRecognizer-clone"></a>}}
\if{latex}{\out{\hypertarget{method-OfflineRecognizer-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{OfflineRecognizer$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
