# Plan 001: Initial R Package Design for sherpa-onnx

**Date**: 2025-11-21
**Status**: Proposed
**Target**: Create R package wrapping sherpa-onnx C++ library for offline speech transcription

## Overview

Create an R package that provides offline speech recognition (WAV file → text) using the sherpa-onnx library. The package will download prebuilt binaries at install time and use HuggingFace Hub for model management.

## Key Design Decisions

### 1. Binary Management

**Install-time binary download** from GitHub releases:
- Source: https://github.com/k2-fsa/sherpa-onnx/releases/tag/v1.12.17
- Target platforms: macOS (universal2), Linux (x64), Windows (x64)
- Files: Shared libraries (~26-40 MB compressed)
- Location: Extract to `inst/include/` and `inst/libs/`
- Fallback: `SHERPA_ONNX_USE_SYSTEM=1` environment variable to use system-installed sherpa-onnx

**Platform-specific downloads**:
- macOS: `sherpa-onnx-v1.12.17-osx-universal2-shared.tar.bz2` (40.7 MB)
- Linux x64: `sherpa-onnx-v1.12.17-linux-x64-shared.tar.bz2` (27.0 MB)
- Windows x64: `sherpa-onnx-v1.12.17-win-x64-shared.tar.bz2` (26.3 MB)

### 2. Model Management with HuggingFace Hub

**Use the `hfhub` R package** for model downloads (cache sharing with other HF consumers).

**Three ways to specify models**:

```r
# 1. Shorthand for popular models
rec <- OfflineRecognizer$new(model = "parakeet-v3")  # default
rec <- OfflineRecognizer$new(model = "whisper-tiny")
rec <- OfflineRecognizer$new(model = "sense-voice")

# 2. Full HuggingFace repo path
rec <- OfflineRecognizer$new(model = "csukuangfj/sherpa-onnx-whisper-tiny.en")

# 3. Local directory path
rec <- OfflineRecognizer$new(model = "/path/to/model-directory")
```

**Shorthand mappings**:
```r
SHORTHAND_MODELS <- list(
  "parakeet-v3" = "csukuangfj/sherpa-onnx-nemo-parakeet-tdt-0.6b-v3-int8",
  "whisper-tiny" = "csukuangfj/sherpa-onnx-whisper-tiny.en",
  "whisper-base" = "csukuangfj/sherpa-onnx-whisper-base.en",
  "sense-voice" = "csukuangfj/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17"
)
```

**Default model**: `"parakeet-v3"` (auto-downloaded on first use if not specified)

**Auto-detect model type** from files present in the model directory:
- Whisper: `encoder.onnx`, `decoder.onnx`, `tokens.txt`
- SenseVoice: `model.onnx` or `model.int8.onnx`, `tokens.txt`
- Paraformer: `model.onnx`, `tokens.txt`
- Transducer: `encoder.onnx`, `decoder.onnx`, `joiner.onnx`, `tokens.txt`

### 3. R6 API Design

**Primary interface**: R6 class for efficient multi-file processing

```r
# Create recognizer (downloads model if needed)
rec <- OfflineRecognizer$new(
  model = "parakeet-v3",     # shorthand, HF repo, or local path
  language = "auto",         # for multilingual models
  num_threads = 1,           # parallel processing threads
  provider = "cpu"           # or "cuda", "coreml"
)

# Transcribe single file
result <- rec$transcribe("audio.wav")
# Returns: list(
#   text = "transcribed text",
#   tokens = c("token1", "token2", ...),
#   timestamps = c(0.0, 0.5, ...),
#   language = "en",           # if detected
#   emotion = NULL,            # if supported by model
#   json = "{...}"             # full result as JSON
# )

# Transcribe multiple files (batch processing)
results <- rec$transcribe_batch(c("file1.wav", "file2.wav", "file3.wav"))
# Returns: list of results

# Get model info
rec$model_info()
# Returns: list(model_path = "...", model_type = "paraformer", ...)

# Cleanup (automatic on garbage collection)
rec$finalize()
```

### 4. C++/R Integration with cpp11

**External pointers** for C++ object lifecycle:
- Wrap `SherpaOnnxOfflineRecognizer*` as R external pointer
- Use finalizers for automatic cleanup
- cpp11's `r_string`, `writable::list` for data exchange

**Key C++ functions** (using sherpa-onnx C API):
```cpp
[[cpp11::register]]
SEXP create_offline_recognizer_(std::string model_dir,
                                 std::string model_type,
                                 int num_threads,
                                 std::string provider);

[[cpp11::register]]
cpp11::list transcribe_wav_(SEXP recognizer_xptr, std::string wav_path);

[[cpp11::register]]
void destroy_recognizer_(SEXP recognizer_xptr);

[[cpp11::register]]
cpp11::list read_wav_(std::string wav_path);
```

### 5. Package Structure

```
sherpa-onnx-r/
├── CLAUDE.md
├── plans/
│   └── 001-INITIAL-DESIGN.md   # This document
├── DESCRIPTION                  # Package metadata (Imports: R6, hfhub, cpp11, rappdirs)
├── NAMESPACE                    # Package exports (generated by roxygen2)
├── .Rbuildignore
├── .gitignore
├── README.md
├── configure                    # Unix: download/extract binaries, generate Makevars
├── configure.win                # Windows: download/extract binaries, generate Makevars
├── cleanup                      # Remove generated files
├── R/
│   ├── install.R               # Binary download functions
│   ├── model.R                 # Model resolution (shorthand→HF, HF download, auto-detect)
│   ├── recognizer.R            # R6 OfflineRecognizer class
│   ├── transcribe.R            # Convenience functions (optional simple API)
│   ├── utils.R                 # Helper functions
│   └── zzz.R                   # .onLoad, .onAttach hooks
├── src/
│   ├── Makevars.in             # Template for Unix (linking flags)
│   ├── Makevars.win            # Template for Windows (linking flags)
│   ├── cpp11.cpp               # cpp11 registration (auto-generated by cpp11::cpp_register)
│   ├── recognizer.cpp          # C++ wrapper for recognizer
│   ├── audio.cpp               # Audio I/O utilities (WAV reading)
│   └── utils.cpp               # C++ utilities
├── inst/
│   ├── include/                # Downloaded sherpa-onnx headers (c-api/c-api.h)
│   └── libs/                   # Downloaded shared libraries (.so/.dylib/.dll)
├── man/                        # Documentation (generated by roxygen2)
│   ├── OfflineRecognizer.Rd
│   └── ...
└── tests/
    └── testthat/
        └── test-recognizer.R
```

## Implementation Steps

### Phase 1: Package Skeleton & Binary Download
1. ✓ Create `CLAUDE.md` with sherpa-onnx source location
2. Create `DESCRIPTION` file (dependencies: R6, hfhub, cpp11, rappdirs)
3. Create `.Rbuildignore`, `.gitignore`
4. Create `configure` script (detect platform, download binaries, extract, generate Makevars)
5. Create `configure.win` script (Windows version)
6. Create `cleanup` script
7. Create `src/Makevars.in` and `src/Makevars.win` templates

### Phase 2: Model Management
8. Implement `R/model.R`:
   - `resolve_model()`: shorthand → HF repo → local path
   - `download_hf_model()`: use hfhub to download model files
   - `detect_model_type()`: auto-detect from files in directory
   - `get_model_config()`: create sherpa-onnx config based on model type

### Phase 3: C++ Integration
9. Implement `src/recognizer.cpp`:
   - `create_offline_recognizer_()`: create recognizer from config
   - `transcribe_wav_()`: transcribe WAV file
   - `destroy_recognizer_()`: cleanup
10. Implement `src/audio.cpp`:
   - Wrapper for `SherpaOnnxReadWave()`
   - Audio format validation
11. Run `cpp11::cpp_register()` to generate `src/cpp11.cpp`

### Phase 4: R6 Class
12. Implement `R/recognizer.R`:
   - `OfflineRecognizer` R6 class
   - `$new()`: resolve model, create recognizer
   - `$transcribe()`: single file transcription
   - `$transcribe_batch()`: batch processing
   - `$model_info()`: get model metadata
   - `$finalize()`: cleanup

### Phase 5: Utilities & Documentation
13. Implement `R/utils.R`: helper functions
14. Implement `R/zzz.R`: package hooks, startup messages
15. Write `README.md` with usage examples
16. Add roxygen2 documentation to all functions
17. Generate man pages with `devtools::document()`

### Phase 6: Testing
18. Create `tests/testthat/test-model.R`: test model resolution
19. Create `tests/testthat/test-recognizer.R`: test transcription
20. Add test fixtures (small WAV file)

## Technical Details

### Configure Script Logic (configure)

```bash
#!/bin/bash

# Check for SHERPA_ONNX_USE_SYSTEM flag
if [ "$SHERPA_ONNX_USE_SYSTEM" = "1" ]; then
  echo "Using system-installed sherpa-onnx"
  # Try pkg-config
  PKG_CFLAGS=$(pkg-config --cflags sherpa-onnx 2>/dev/null)
  PKG_LIBS=$(pkg-config --libs sherpa-onnx 2>/dev/null)

  if [ $? -ne 0 ]; then
    echo "ERROR: pkg-config could not find sherpa-onnx"
    echo "Please install sherpa-onnx or unset SHERPA_ONNX_USE_SYSTEM"
    exit 1
  fi
else
  # Detect platform
  OS=$(uname -s)
  ARCH=$(uname -m)

  case "$OS" in
    Darwin)
      PLATFORM="osx-universal2"
      ARCHIVE="sherpa-onnx-v1.12.17-osx-universal2-shared.tar.bz2"
      ;;
    Linux)
      if [ "$ARCH" = "x86_64" ]; then
        PLATFORM="linux-x64"
        ARCHIVE="sherpa-onnx-v1.12.17-linux-x64-shared.tar.bz2"
      else
        echo "ERROR: Unsupported architecture: $ARCH"
        echo "Set SHERPA_ONNX_USE_SYSTEM=1 to use system sherpa-onnx"
        exit 1
      fi
      ;;
    *)
      echo "ERROR: Unsupported OS: $OS"
      exit 1
      ;;
  esac

  # Download
  URL="https://github.com/k2-fsa/sherpa-onnx/releases/download/v1.12.17/$ARCHIVE"
  echo "Downloading sherpa-onnx binaries from $URL"

  curl -L -o "$ARCHIVE" "$URL"

  # Extract
  tar xjf "$ARCHIVE"

  # Move to inst/
  mkdir -p inst/include inst/libs
  cp -r sherpa-onnx-*/include/* inst/include/
  cp -r sherpa-onnx-*/lib/* inst/libs/

  # Cleanup
  rm -rf "$ARCHIVE" sherpa-onnx-*

  # Set flags for Makevars
  PKG_CFLAGS="-I../inst/include"
  PKG_LIBS="-L../inst/libs -lsherpa-onnx -Wl,-rpath,'\$\$ORIGIN/../libs'"
fi

# Generate src/Makevars
sed -e "s|@PKG_CFLAGS@|$PKG_CFLAGS|" \
    -e "s|@PKG_LIBS@|$PKG_LIBS|" \
    src/Makevars.in > src/Makevars

echo "Configuration complete"
```

### Model Resolution Logic (R/model.R)

```r
resolve_model <- function(model = "parakeet-v3") {
  # 1. Check if it's a local path
  if (dir.exists(model)) {
    message("Using local model at: ", model)
    return(list(
      type = "local",
      path = normalizePath(model),
      model_type = detect_model_type(model)
    ))
  }

  # 2. Check if it's a HuggingFace repo (contains "/")
  if (grepl("/", model)) {
    hf_repo <- model
  } else {
    # 3. Treat as shorthand
    hf_repo <- SHORTHAND_MODELS[[model]]
    if (is.null(hf_repo)) {
      stop("Unknown model shorthand: ", model,
           "\nAvailable: ", paste(names(SHORTHAND_MODELS), collapse = ", "))
    }
  }

  # Download from HuggingFace
  message("Downloading model from HuggingFace: ", hf_repo)
  model_path <- download_hf_model(hf_repo)

  return(list(
    type = "huggingface",
    repo = hf_repo,
    path = model_path,
    model_type = detect_model_type(model_path)
  ))
}

detect_model_type <- function(model_dir) {
  files <- list.files(model_dir)

  if ("encoder.onnx" %in% files && "decoder.onnx" %in% files) {
    if ("joiner.onnx" %in% files) {
      return("transducer")
    } else {
      return("whisper")
    }
  } else if (any(grepl("^model.*\\.onnx$", files))) {
    # Could be paraformer or sense-voice
    # Check for language-specific indicators in filenames
    if (any(grepl("sense-?voice", files, ignore.case = TRUE))) {
      return("sense-voice")
    } else {
      return("paraformer")
    }
  }

  stop("Could not detect model type from files in: ", model_dir)
}
```

### R6 OfflineRecognizer Class (R/recognizer.R)

```r
#' Offline Speech Recognizer
#'
#' @description
#' R6 class for offline speech recognition using sherpa-onnx.
#'
#' @export
OfflineRecognizer <- R6::R6Class(
  "OfflineRecognizer",

  private = list(
    recognizer_ptr = NULL,
    model_info_cache = NULL
  ),

  public = list(
    #' @description
    #' Create a new offline recognizer
    #' @param model Model specification (shorthand, HF repo, or local path)
    #' @param language Language code (for multilingual models)
    #' @param num_threads Number of threads for inference
    #' @param provider Execution provider ("cpu", "cuda", "coreml")
    initialize = function(model = "parakeet-v3",
                         language = "auto",
                         num_threads = 1,
                         provider = "cpu") {

      # Resolve model
      model_info <- resolve_model(model)
      private$model_info_cache <- model_info

      # Create recognizer
      private$recognizer_ptr <- create_offline_recognizer_(
        model_dir = model_info$path,
        model_type = model_info$model_type,
        num_threads = num_threads,
        provider = provider,
        language = language
      )
    },

    #' @description
    #' Transcribe a WAV file
    #' @param wav_path Path to WAV file
    #' @return List with transcription results
    transcribe = function(wav_path) {
      if (!file.exists(wav_path)) {
        stop("WAV file not found: ", wav_path)
      }

      transcribe_wav_(private$recognizer_ptr, wav_path)
    },

    #' @description
    #' Transcribe multiple WAV files
    #' @param wav_paths Vector of WAV file paths
    #' @return List of transcription results
    transcribe_batch = function(wav_paths) {
      lapply(wav_paths, self$transcribe)
    },

    #' @description
    #' Get model information
    #' @return List with model metadata
    model_info = function() {
      private$model_info_cache
    },

    #' @description
    #' Cleanup resources
    finalize = function() {
      if (!is.null(private$recognizer_ptr)) {
        destroy_recognizer_(private$recognizer_ptr)
        private$recognizer_ptr <- NULL
      }
    }
  )
)
```

## Dependencies

### R Packages (DESCRIPTION Imports)
- **R6** (>= 2.5.0): R6 class system
- **hfhub** (>= 0.1.0): HuggingFace Hub downloads
- **cpp11** (>= 0.4.0): C++/R interface
- **rappdirs** (>= 0.3.0): Cross-platform directory paths

### System Requirements
- **C++17 compiler**: For building cpp11 wrappers
- **sherpa-onnx binaries**: Downloaded automatically or via system install

## Open Questions

1. **Error handling**: How should we handle errors from the C API? Should we wrap them in R conditions?
2. **Progress reporting**: Should we add progress bars for batch transcription?
3. **Streaming API**: Should we add support for online/streaming recognition in the future?
4. **GPU support**: Should we make it easy to use CUDA/CoreML providers?
5. **Model configuration**: Should we expose more model-specific parameters (e.g., beam size, temperature)?

## Success Criteria

- [ ] Package installs successfully on macOS, Linux, Windows
- [ ] Binary download works or falls back to system install
- [ ] Can transcribe a WAV file with default model
- [ ] All three model specification methods work
- [ ] Models cached correctly via hfhub
- [ ] Auto-detection identifies model types correctly
- [ ] R6 class properly manages C++ object lifecycle
- [ ] Documentation is clear and includes examples
- [ ] Basic tests pass

## References

- sherpa-onnx source: https://github.com/k2-fsa/sherpa-onnx
- sherpa-onnx releases: https://github.com/k2-fsa/sherpa-onnx/releases
- sherpa-onnx C API: `sherpa-onnx/c-api/c-api.h`
- C API example: `c-api-examples/sense-voice-c-api.c`
- HuggingFace models: https://huggingface.co/models?search=sherpa-onnx
